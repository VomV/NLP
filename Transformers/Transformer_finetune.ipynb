{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finetuning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hidden states are trained along with a classification head using a small labeled dataset. This allows hidden states to adapt to the dataset and achieve better performance on the dataset of interest. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finetuning a DistilBert model with emotions dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from transformers import Trainer, TrainingArguments\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.bias', 'vocab_projector.weight', 'vocab_projector.bias', 'vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'classifier.bias', 'classifier.weight', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "num_labels=6\n",
    "model_ckpt = 'distilbert-base-uncased'\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_ckpt, num_labels=num_labels).to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification weights are not initialised, so the model needs to be trained for classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load emotions dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration SetFit--emotion-e444b7640ce3116e\n",
      "Found cached dataset json (/home/vivek/.cache/huggingface/datasets/SetFit___json/SetFit--emotion-e444b7640ce3116e/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d60fb443c0b4f16be9a272b3d95fdaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "emotions = load_dataset('SetFit/emotion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label', 'label_text'],\n",
       "        num_rows: 16000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label', 'label_text'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'label', 'label_text'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/vivek/.cache/huggingface/datasets/SetFit___json/SetFit--emotion-e444b7640ce3116e/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-2a5326c6c3f4841d.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c970423ca9654b6caa9f39a6f67cc70c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/vivek/.cache/huggingface/datasets/SetFit___json/SetFit--emotion-e444b7640ce3116e/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-4eed9c48a8c5fdbc.arrow\n"
     ]
    }
   ],
   "source": [
    "def tokenize(batch):\n",
    "    return tokenizer(batch['text'], padding=True, truncation=False)\n",
    "    \n",
    "emotions_encoded = emotions.map(tokenize, batched=True, batch_size=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label', 'label_text', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 16000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label', 'label_text', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'label', 'label_text', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotions_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    \n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    f1 = f1_score(labels, preds, average='weighted')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {'accuracy': acc, 'f1': f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "logging_steps = len(emotions_encoded['train'])//batch_size\n",
    "\n",
    "model_name = f\"{model_ckpt}-finetuned-emotion\"\n",
    "training_args = TrainingArguments(\n",
    "                                    output_dir=model_name,\n",
    "                                    num_train_epochs=5,\n",
    "                                    learning_rate=2e-5,\n",
    "                                    per_device_train_batch_size=batch_size,\n",
    "                                    per_device_eval_batch_size=batch_size,\n",
    "                                    weight_decay=0.01,\n",
    "                                    evaluation_strategy='epoch',\n",
    "                                    disable_tqdm=False,\n",
    "                                    logging_steps=logging_steps,\n",
    "                                    log_level='error'\n",
    "                                    \n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label', 'label_text', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 100\n",
       "})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(emotions_encoded['train'].select(range(100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vivek/.local/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "479c15f4a56e4afabeb56b11cdee5e54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "062dde22e58e47bf8d410d15adb38adf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.180893898010254, 'eval_accuracy': 0.62, 'eval_f1': 0.4975704225352112, 'eval_runtime': 1.5187, 'eval_samples_per_second': 65.845, 'eval_steps_per_second': 1.317, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8867129d82284fe3b7e38b33027516c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0538822412490845, 'eval_accuracy': 0.63, 'eval_f1': 0.5056610470275067, 'eval_runtime': 1.482, 'eval_samples_per_second': 67.475, 'eval_steps_per_second': 1.35, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed13831897ad480dada2ff3256e58815",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9980353713035583, 'eval_accuracy': 0.65, 'eval_f1': 0.5596842105263158, 'eval_runtime': 1.4057, 'eval_samples_per_second': 71.137, 'eval_steps_per_second': 1.423, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c54985d6aad445a97e08fef859af1d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9427658319473267, 'eval_accuracy': 0.65, 'eval_f1': 0.5609577464788732, 'eval_runtime': 1.3777, 'eval_samples_per_second': 72.586, 'eval_steps_per_second': 1.452, 'epoch': 4.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc829e904bf84cd8912f77da7ed54fc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9211843609809875, 'eval_accuracy': 0.66, 'eval_f1': 0.5746666666666667, 'eval_runtime': 1.5994, 'eval_samples_per_second': 62.524, 'eval_steps_per_second': 1.25, 'epoch': 5.0}\n",
      "{'train_runtime': 327.2929, 'train_samples_per_second': 15.277, 'train_steps_per_second': 0.244, 'train_loss': 1.0982325553894043, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=80, training_loss=1.0982325553894043, metrics={'train_runtime': 327.2929, 'train_samples_per_second': 15.277, 'train_steps_per_second': 0.244, 'train_loss': 1.0982325553894043, 'epoch': 5.0})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(model=model,\n",
    "                 args=training_args,\n",
    "                 compute_metrics=compute_metrics,\n",
    "                 train_dataset=emotions_encoded['train'].select(range(1000)),\n",
    "                 eval_dataset=emotions_encoded['validation'].select(range(100)),\n",
    "                 tokenizer=tokenizer)\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation of the trained model: Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get predictions on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8aa76975c4924fe4883f76e8a2a0bb7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "PredictionOutput(predictions=array([[ 1.7090542 , -0.60498106, -0.6843202 ,  0.22433458,  0.08855602,\n",
       "        -0.88751745],\n",
       "       [ 1.1857754 , -0.61272955, -0.695687  ,  0.3240202 ,  0.74435234,\n",
       "        -0.65783906],\n",
       "       [-0.66186744,  2.2353747 ,  0.7680528 , -1.0138999 , -0.60349184,\n",
       "        -0.49983332],\n",
       "       ...,\n",
       "       [-0.8918657 ,  2.3773751 ,  0.74762636, -1.0503939 , -0.6029408 ,\n",
       "        -0.3462072 ],\n",
       "       [-0.86393595,  2.447637  ,  0.8352506 , -1.1255658 , -0.69377625,\n",
       "        -0.49454224],\n",
       "       [-0.92508554,  2.3268447 ,  0.6656499 , -1.0438763 , -0.7462544 ,\n",
       "        -0.26178628]], dtype=float32), label_ids=array([0, 0, 2, ..., 1, 1, 1]), metrics={'test_loss': 0.9870486259460449, 'test_accuracy': 0.6715, 'test_f1': 0.6067521686594002, 'test_runtime': 27.2413, 'test_samples_per_second': 73.418, 'test_steps_per_second': 1.175})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_output = trainer.predict(emotions_encoded['validation'])\n",
    "preds_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test_loss': 0.9870486259460449,\n",
       " 'test_accuracy': 0.6715,\n",
       " 'test_f1': 0.6067521686594002,\n",
       " 'test_runtime': 27.2413,\n",
       " 'test_samples_per_second': 73.418,\n",
       " 'test_steps_per_second': 1.175}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_output.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = np.argmax(preds_output.predictions, axis=1)\n",
    "y_valid = preds_output.label_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sadness', 'joy', 'love', 'anger', 'fear', 'surprise']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_map = list(set(zip(emotions['train']['label'], emotions['train']['label_text'])))\n",
    "label_map.sort(key= lambda pair: pair[0])\n",
    "labels = [l[1] for l in label_map]\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 12\u001b[0m\n\u001b[1;32m      8\u001b[0m     disp\u001b[39m.\u001b[39mplot(cmap\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mBlues\u001b[39m\u001b[39m'\u001b[39m, values_format\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.2f\u001b[39m\u001b[39m'\u001b[39m, ax\u001b[39m=\u001b[39max, colorbar\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m      9\u001b[0m     plt\u001b[39m.\u001b[39mshow()\n\u001b[0;32m---> 12\u001b[0m plot_confusion_mat(y_valid, y_preds, labels)\n",
      "Cell \u001b[0;32mIn[50], line 6\u001b[0m, in \u001b[0;36mplot_confusion_mat\u001b[0;34m(y_true, y_pred, labels)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mplot_confusion_mat\u001b[39m(y_true, y_pred, labels):\n\u001b[1;32m      5\u001b[0m     cm \u001b[39m=\u001b[39m confusion_matrix(y_true, y_pred, normalize\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtrue\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m     fig, ax \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39msubplots(figsize\u001b[39m=\u001b[39m(\u001b[39m6\u001b[39m,\u001b[39m6\u001b[39m))\n\u001b[1;32m      7\u001b[0m     disp \u001b[39m=\u001b[39m ConfusionMatrixDisplay(confusion_matrix\u001b[39m=\u001b[39mcm, display_labels\u001b[39m=\u001b[39mlabels)\n\u001b[1;32m      8\u001b[0m     disp\u001b[39m.\u001b[39mplot(cmap\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mBlues\u001b[39m\u001b[39m'\u001b[39m, values_format\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.2f\u001b[39m\u001b[39m'\u001b[39m, ax\u001b[39m=\u001b[39max, colorbar\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "import matplotlib.pyplot as plot_confusion_mat\n",
    "\n",
    "def plot_confusion_mat(y_true, y_pred, labels):\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred, normalize='true')\n",
    "    fig, ax = plt.subplots(figsize=(6,6))\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "    disp.plot(cmap='Blues', values_format='.2f', ax=ax, colorbar=False)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_confusion_mat(y_valid, y_preds, labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dddab157190c3c29c7bfa9724dd2612e80e7d4a281bb7f76e54f36d2e23abd8a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
