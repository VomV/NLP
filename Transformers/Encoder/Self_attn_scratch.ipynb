{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaled Dot Product Attn mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create index of an input text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = 'Life is too short to be afraid'\n",
    "\n",
    "w_ix = {s:i for i, s in enumerate(sentence.split())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Life': 0, 'is': 1, 'too': 2, 'short': 3, 'to': 4, 'be': 5, 'afraid': 6}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_int = torch.tensor([w_ix[s] for s in sentence.replace(',', '').split()])\n",
    "sent_int"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Embeddings for each word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7, 16])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "embed = torch.nn.Embedding(7, 16)\n",
    "embedded_sentence = embed(sent_int).detach()\n",
    "\n",
    "print(embedded_sentence.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query, Key and Value vectors\n",
    "- Assumed to be of same dim here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = embedded_sentence.shape[1]\n",
    "U_query = torch.rand(d, d)\n",
    "U_key = torch.rand(d, d)\n",
    "U_value = torch.rand(d, d)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attn vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_2 = embedded_sentence[2]\n",
    "q_2 = U_query.matmul(x_2)\n",
    "k_2 = U_key.matmul(x_2)\n",
    "v_2 = U_value.matmul(x_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16])\n"
     ]
    }
   ],
   "source": [
    "print(q_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7, 16])\n",
      "torch.Size([7, 16])\n"
     ]
    }
   ],
   "source": [
    "keys = U_key.matmul(embedded_sentence.T).T\n",
    "values = U_key.matmul(embedded_sentence.T).T\n",
    "\n",
    "print(keys.shape)\n",
    "print(values.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unnormalized attn weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([   7.2290, -163.6516,   85.0492,   32.2506,  -51.0580,    5.9121,\n",
      "         -42.7785])\n"
     ]
    }
   ],
   "source": [
    "omg_2 = q_2.matmul(keys.T)\n",
    "print(omg_2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute Attn Scores\n",
    "- Apply softmax\n",
    "- Scale by 1/sqrt(dk) (dk = d here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3.5545e-09, 9.9459e-28, 1.0000e+00, 1.8512e-06, 1.6685e-15, 2.5573e-09,\n",
      "        1.3222e-14])\n"
     ]
    }
   ],
   "source": [
    "attn_weights_2 = F.softmax(omg_2/d**0.5, dim=0)\n",
    "print(attn_weights_2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, compute Context Vector: atten weighted vector for input x[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-2.6558, -2.1991, -1.7659, -2.7137, -2.1071, -2.3546, -3.4613, -2.4942,\n",
      "        -3.1013, -3.5964, -1.6744, -2.1051, -2.5072, -2.5132, -1.1317, -3.7972])\n"
     ]
    }
   ],
   "source": [
    "context_2 = attn_weights_2.matmul(values)\n",
    "print(context_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multi-Headed Attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "head = 3\n",
    "\n",
    "multihead_U_query = torch.rand(head, d, d)\n",
    "multihead_U_key = torch.rand(head, d, d)\n",
    "multihead_U_value = torch.rand(head, d, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.5047, -1.7224, -3.2717, -1.0175, -3.1253, -3.4689, -1.0962, -2.1339,\n",
      "         -1.5737, -3.9808, -3.3262, -2.3460, -1.2702,  0.7139, -0.4141, -3.3865],\n",
      "        [-2.1503, -1.2775, -1.4216, -3.0825, -0.4842, -5.5525, -2.6342, -1.1775,\n",
      "         -2.0682, -3.9901, -0.6912, -3.3454, -3.1575, -0.9453, -2.6569, -2.6200],\n",
      "        [-2.2139, -0.1555, -1.1641, -1.1115, -2.9687, -1.7173, -2.8947, -2.9682,\n",
      "         -2.1936, -3.2098, -2.8411, -0.4260, -3.3345, -2.7292, -3.0808, -3.1608]])\n"
     ]
    }
   ],
   "source": [
    "multihead_query_2 = multihead_U_query.matmul(x_2)\n",
    "print(multihead_query_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "multihead_key_2 = multihead_U_key.matmul(x_2)\n",
    "multihead_value_2 = multihead_U_value.matmul(x_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 7])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " embedded_sentence.T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 16, 7])\n"
     ]
    }
   ],
   "source": [
    "stacked_input = embedded_sentence.T.repeat(3, 1, 1)\n",
    "print(stacked_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 16, 7])\n",
      "torch.Size([3, 16, 7])\n"
     ]
    }
   ],
   "source": [
    "multihead_keys = torch.bmm(multihead_U_key, stacked_input)\n",
    "multihead_values = torch.bmm(multihead_U_value, stacked_input)\n",
    "print(multihead_keys.shape)\n",
    "print(multihead_values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dddab157190c3c29c7bfa9724dd2612e80e7d4a281bb7f76e54f36d2e23abd8a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
