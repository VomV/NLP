{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read all words\n",
    "\n",
    "words = open('names.txt', 'r').read().splitlines()\n",
    "words[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32033"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "\n",
    "itos = {i:s for s,i in stoi.items()}\n",
    "vocab_size = len(itos)\n",
    "print(itos)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182625, 3]) torch.Size([182625])\n",
      "torch.Size([22655, 3]) torch.Size([22655])\n",
      "torch.Size([22866, 3]) torch.Size([22866])\n"
     ]
    }
   ],
   "source": [
    "block_size = 3\n",
    "\n",
    "def build_dataset(words):\n",
    "\n",
    "    X, Y = [], []\n",
    "    for w in words:\n",
    "        context = [0] * block_size\n",
    "        for ch in w + '.':\n",
    "            ix = stoi[ch]\n",
    "            X.append(context)\n",
    "            Y.append(ix)\n",
    "            context = context[1:] + [ix] #crop and append\n",
    "\n",
    "    X = torch.tensor(X)\n",
    "    Y = torch.tensor(Y)\n",
    "    print(X.shape, Y.shape)\n",
    "    return X, Y\n",
    "\n",
    "\n",
    "random.seed(42)\n",
    "random.shuffle(words)\n",
    "n1 = int(0.8*len(words))\n",
    "n2 = int(0.9*len(words))\n",
    "X_train, Y_train = build_dataset(words[:n1])\n",
    "X_dev, Y_dev = build_dataset(words[n1:n2])\n",
    "X_test, Y_test = build_dataset(words[n2:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utility func to compare grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cmp(s, dt, t):\n",
    "    ex = torch.all(dt == t.grad).item()\n",
    "    app = torch.allclose(dt, t.grad)\n",
    "    maxdiff = (dt - t.grad).abs().max().item()\n",
    "    print(f'{s:15s} | exact: {str(ex):5s} | approximate: {str(app):5s} | maxdiff: {maxdiff}')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4137\n"
     ]
    }
   ],
   "source": [
    "n_embed = 10 #dim of the char embeddings\n",
    "n_hidden = 64 #num of neurons in the hidden layer of MLP\n",
    "\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "C = torch.randn((vocab_size, n_embed), generator=g)\n",
    "\n",
    "#Layer1\n",
    "W1 = torch.randn((block_size*n_embed, n_hidden), generator=g) * (5/3)/((n_embed*block_size)**0.5) #kaining init\n",
    "b1 = torch.randn(n_hidden, generator=g) * 0.1 #bias is optional here since we use batchnorm after this which cancels out bias term\n",
    "\n",
    "#Layer2\n",
    "W2 = torch.randn((n_hidden, vocab_size), generator=g) * 0.1\n",
    "b2 = torch.randn(vocab_size, generator=g) * 0.1\n",
    "\n",
    "#BatchNorm Params\n",
    "bngain = torch.randn((1, n_hidden))*0.1 + 1.0\n",
    "bnbias = torch.randn((1, n_hidden))* 0.1\n",
    "\n",
    "\n",
    "parameters = [C, W1, b1, W2, b2, bngain, bnbias]\n",
    "print(sum(p.nelement() for p in parameters))\n",
    "for p in parameters:\n",
    "    p.requires_grad = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "n = batch_size\n",
    "\n",
    "#construct a minibatch\n",
    "ix = torch.randint(0, X_train.shape[0], (batch_size, ), generator=g)\n",
    "Xb, Yb = X_train[ix], Y_train[ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.3490, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#forward pass, split into small steps\n",
    "\n",
    "emb = C[Xb]\n",
    "embcat = emb.view(emb.shape[0], -1)\n",
    "\n",
    "#Linear Layer 1\n",
    "h_pre_bn = embcat @ W1 + b1 #hidden layer preact\n",
    "\n",
    "#Batchnorm layer\n",
    "bnmeani = 1/n * h_pre_bn.sum(0, keepdim=True)\n",
    "bndiff = h_pre_bn - bnmeani\n",
    "bndiff2 = bndiff**2\n",
    "bnvar = 1/(n-1) * (bndiff2).sum(0, keepdim=True) #Bessel's correctn, div by n-1 not n\n",
    "bnvar_inv = (bnvar + 1e-5)**-0.5\n",
    "bnraw = bndiff * bnvar_inv\n",
    "h_pre_act = bngain * bnraw + bnbias\n",
    "\n",
    "#Non linearity\n",
    "h = torch.tanh(h_pre_act) #hidden layer\n",
    "\n",
    "#Linear Layer 2\n",
    "logits = h @ W2 + b2 #output layer\n",
    "\n",
    "#cross entropy loss\n",
    "logit_maxes = logits.max(1, keepdim=True).values\n",
    "norm_logits = logits - logit_maxes #subs max for stability\n",
    "counts = norm_logits.exp()\n",
    "counts_sum = counts.sum(1, keepdim=True)\n",
    "counts_sum_inv = counts_sum**-1 #if 1/counts_sum is used, backprop wont be exact\n",
    "probs = counts * counts_sum_inv\n",
    "logprobs = probs.log()\n",
    "loss = -logprobs[range(n), Yb].mean()\n",
    "\n",
    "#Pytorch backward pass\n",
    "for p in parameters:\n",
    "    p.grad = None\n",
    "\n",
    "for t in [emb, embcat, h_pre_bn, bnmeani, bndiff, bndiff2, bnvar, \n",
    "          bnvar_inv, bnraw, h_pre_act, h, logits, logit_maxes, norm_logits, counts, \n",
    "          counts_sum, counts_sum_inv, probs, logprobs, loss]:\n",
    "    t.retain_grad()\n",
    "\n",
    "loss.backward()\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Backpropagate manually"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Cal grads of each of the intermediate variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logprobs        | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "#dlogprobs = d(Loss)/dlogprobs\n",
    "\n",
    "#loss = -(a + b + c)/3 ==> dloss/da = -1/3\n",
    "\n",
    "#a, b, c in logprobs participate in cal loss for rest grad will be zero\n",
    "\n",
    "dlogprobs = torch.zeros_like(logprobs)\n",
    "dlogprobs[range(n), Yb] = -1.0/n # n is the batchsize here, from each batch one prob contributes to loss, as indexed by Yb\n",
    "\n",
    "#check with pytorch\n",
    "cmp('logprobs', dlogprobs, logprobs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probs           | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "#dprobs = local der * dlogprobs -> 1/x * dlogprobs\n",
    "\n",
    "dprobs = (1.0/probs) * dlogprobs\n",
    "cmp('probs', dprobs, probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- dprobs will be boosted if probs is low and dlogprobs is non zero, which means cases where correct label has low prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 27]), torch.Size([32, 1]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts.shape, counts_sum_inv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 27])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dprobs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count_sum_inv is broadcasted to mul with counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counts          | exact: False | approximate: False | maxdiff: 0.005788503214716911\n",
      "counts_sum_inv  | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "#dcounts = count_sum_inv * dprobs \n",
    "#dcounts_sum_inv = sum(counts * dprobs, 1) : also since this is broadcasted to 27 cols, we sum the grad\n",
    "\n",
    "dcounts1 = counts_sum_inv * dprobs\n",
    "dcounts_sum_inv = (counts * dprobs).sum(1, keepdim=True)\n",
    "\n",
    "cmp('counts', dcounts1, counts)\n",
    "cmp('counts_sum_inv', dcounts_sum_inv, counts_sum_inv)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- dcounts does not match here since it is being used twice, to cal count_sum also, so grad will flow in from there as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counts_sum      | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "#dcount_sum = -counts_sum**-2 * dcounts_sum_inv\n",
    "\n",
    "dcounts_sum = -counts_sum**-2 * dcounts_sum_inv\n",
    "cmp('counts_sum', dcounts_sum, counts_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counts          | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "#2nd part of dcounts = 1 * dcounts_sum, grad dlows equally to all elements of the sum\n",
    "\n",
    "dcounts2 = 1 * dcounts_sum\n",
    "dcounts = dcounts1 + dcounts2\n",
    "cmp('counts', dcounts, counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dnorm_logits    | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "#dnorm_logits\n",
    "\n",
    "dnorm_logits = counts * dcounts\n",
    "cmp('dnorm_logits', dnorm_logits, norm_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dlogit_maxes    | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "dlogits1        | exact: False | approximate: True  | maxdiff: 7.2177499532699585e-09\n"
     ]
    }
   ],
   "source": [
    "#dlogit_maxes; broadcasting happening here\n",
    "\n",
    "dlogit_maxes = (-1 * dnorm_logits).sum(1, keepdim=True)\n",
    "dlogits1 = dnorm_logits.clone()\n",
    "\n",
    "cmp('dlogit_maxes', dlogit_maxes, logit_maxes)\n",
    "cmp('dlogits1', dlogits1, logits)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.3283e-09],\n",
       "        [-3.7253e-09],\n",
       "        [ 3.7253e-09],\n",
       "        [ 0.0000e+00],\n",
       "        [ 2.3283e-09],\n",
       "        [ 1.1642e-09],\n",
       "        [ 2.7940e-09],\n",
       "        [-4.6566e-10],\n",
       "        [-5.1223e-09],\n",
       "        [-1.8626e-09],\n",
       "        [-4.6566e-09],\n",
       "        [-3.4925e-09],\n",
       "        [-1.6298e-09],\n",
       "        [-4.6566e-09],\n",
       "        [ 4.1910e-09],\n",
       "        [ 0.0000e+00],\n",
       "        [-9.3132e-10],\n",
       "        [ 7.2177e-09],\n",
       "        [-1.6298e-09],\n",
       "        [ 4.6566e-10],\n",
       "        [-4.6566e-10],\n",
       "        [ 0.0000e+00],\n",
       "        [-1.6298e-09],\n",
       "        [-1.3970e-09],\n",
       "        [ 5.5879e-09],\n",
       "        [-4.6566e-10],\n",
       "        [ 5.3551e-09],\n",
       "        [-4.6566e-10],\n",
       "        [-6.5193e-09],\n",
       "        [-9.3132e-10],\n",
       "        [-1.3970e-09],\n",
       "        [ 6.5193e-09]], grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlogit_maxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- dlogit_maxes is very small and it should be since its substracted from logits and it should not impact probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dlogits         | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "#dlogits; second part; here grad should be only for max value and rest should be zero\n",
    "\n",
    "dlogits2 = F.one_hot(logits.max(1).indices, num_classes=logits.shape[1]) * dlogit_maxes\n",
    "dlogits = dlogits1 + dlogits2\n",
    "cmp('dlogits', dlogits, logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7ff3e78cb700>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#indices where max value resides is 1, rest is zero\n",
    "plt.imshow(F.one_hot(logits.max(1).indices, num_classes=logits.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 27]),\n",
       " torch.Size([32, 64]),\n",
       " torch.Size([64, 27]),\n",
       " torch.Size([27]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlogits.shape, h.shape, W2.shape, b2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([27, 64])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W2.T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dh              | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "#dh; logits = h@W + b; so dl/dh = dl/dlogits @ W.T; dh will be same dim as h\n",
    "dh = dlogits @  W2.T\n",
    "cmp('dh', dh, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dW2             | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "#dW2 should be same shape as W2 ie 64, 27; h.T @ dlogits\n",
    "dW2 = h.T @ dlogits\n",
    "cmp('dW2', dW2, W2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "db2             | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "#db2\n",
    "\n",
    "db2 = dlogits.sum(0)\n",
    "cmp('db2', db2, b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dh_pre_act      | exact: False | approximate: True  | maxdiff: 4.656612873077393e-10\n"
     ]
    }
   ],
   "source": [
    "#dh_pre_act; backprop through tanh\n",
    "\n",
    "dh_pre_act = (1.0 - h**2) * dh\n",
    "cmp('dh_pre_act', dh_pre_act, h_pre_act)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 64]),\n",
       " torch.Size([1, 64]),\n",
       " torch.Size([32, 64]),\n",
       " torch.Size([1, 64]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_pre_act.shape, bngain.shape, bnraw.shape, bnbias.shape, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dbngain         | exact: False | approximate: True  | maxdiff: 2.7939677238464355e-09\n"
     ]
    }
   ],
   "source": [
    "#bngain; h_pre_act = bngain * bnraw + bnbias; this is elementwise mul so its simpler\n",
    "\n",
    "dbngain = (bnraw * dh_pre_act).sum(0, keepdim=True)\n",
    "cmp('dbngain', dbngain, bngain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dbnraw          | exact: False | approximate: True  | maxdiff: 6.984919309616089e-10\n"
     ]
    }
   ],
   "source": [
    "dbnraw = (bngain * dh_pre_act)\n",
    "cmp('dbnraw', dbnraw, bnraw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dbnbias         | exact: False | approximate: True  | maxdiff: 4.6566128730773926e-09\n"
     ]
    }
   ],
   "source": [
    "dbnbias = dh_pre_act.sum(0, keepdim=True)\n",
    "cmp('dbnbias', dbnbias, bnbias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Backprop through batch norm layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 64]), torch.Size([32, 64]), torch.Size([1, 64]))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bnraw.shape, bndiff.shape, bnvar_inv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dbndiff         | exact: False | approximate: False | maxdiff: 0.0011039187666028738\n"
     ]
    }
   ],
   "source": [
    "#dbndiff1\n",
    "\n",
    "dbndiff1 = dbnraw * bnvar_inv\n",
    "cmp('dbndiff', dbndiff1, bndiff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dbnvar_inv      | exact: False | approximate: True  | maxdiff: 2.0954757928848267e-09\n"
     ]
    }
   ],
   "source": [
    "#dbnvar_inv\n",
    "\n",
    "dbnvar_inv = (bndiff * dbnraw).sum(0, keepdim=True)\n",
    "cmp('dbnvar_inv', dbnvar_inv, bnvar_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dbnvar          | exact: False | approximate: True  | maxdiff: 9.313225746154785e-10\n"
     ]
    }
   ],
   "source": [
    "#dbnvar\n",
    "\n",
    "dbnvar = (-0.5*(bnvar + 1e-5)**-1.5) * dbnvar_inv\n",
    "cmp('dbnvar', dbnvar, bnvar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 64]), torch.Size([32, 64]))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bnvar.shape, bndiff2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dbndiff2        | exact: False | approximate: True  | maxdiff: 2.9103830456733704e-11\n"
     ]
    }
   ],
   "source": [
    "#dbndiff2\n",
    "\n",
    "dbndiff2 = (1.0/(n-1))*torch.ones_like(bndiff2) * dbnvar\n",
    "cmp('dbndiff2', dbndiff2, bndiff2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dbndiff         | exact: False | approximate: True  | maxdiff: 4.656612873077393e-10\n"
     ]
    }
   ],
   "source": [
    "# dbndiff\n",
    "\n",
    "dbndiff_2 = 2*bndiff * dbndiff2\n",
    "dbndiff = dbndiff1 + dbndiff_2\n",
    "cmp('dbndiff', dbndiff, bndiff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 64]), torch.Size([32, 64]), torch.Size([1, 64]))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bndiff.shape, h_pre_bn.shape, bnmeani.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dh_pre_bn       | exact: False | approximate: False | maxdiff: 0.0010791255626827478\n",
      "dbnmeani        | exact: False | approximate: True  | maxdiff: 1.862645149230957e-09\n"
     ]
    }
   ],
   "source": [
    "#bndiff = h_pre_bn - bnmeani\n",
    "\n",
    "dh_pre_bn = dbndiff.clone()\n",
    "cmp('dh_pre_bn', dh_pre_bn, h_pre_bn)\n",
    "dbnmeani = (-dbndiff).sum(0)\n",
    "cmp('dbnmeani', dbnmeani, bnmeani)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dh_pre_bn       | exact: False | approximate: True  | maxdiff: 4.656612873077393e-10\n"
     ]
    }
   ],
   "source": [
    "#dh_pre_bn; second part\n",
    "\n",
    "dh_pre_bn += (1.0/n)*torch.ones_like(h_pre_bn) * dbnmeani\n",
    "cmp('dh_pre_bn', dh_pre_bn, h_pre_bn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
