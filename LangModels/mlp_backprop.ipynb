{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read all words\n",
    "\n",
    "words = open('names.txt', 'r').read().splitlines()\n",
    "words[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32033"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "\n",
    "itos = {i:s for s,i in stoi.items()}\n",
    "vocab_size = len(itos)\n",
    "print(itos)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182625, 3]) torch.Size([182625])\n",
      "torch.Size([22655, 3]) torch.Size([22655])\n",
      "torch.Size([22866, 3]) torch.Size([22866])\n"
     ]
    }
   ],
   "source": [
    "block_size = 3\n",
    "\n",
    "def build_dataset(words):\n",
    "\n",
    "    X, Y = [], []\n",
    "    for w in words:\n",
    "        context = [0] * block_size\n",
    "        for ch in w + '.':\n",
    "            ix = stoi[ch]\n",
    "            X.append(context)\n",
    "            Y.append(ix)\n",
    "            context = context[1:] + [ix] #crop and append\n",
    "\n",
    "    X = torch.tensor(X)\n",
    "    Y = torch.tensor(Y)\n",
    "    print(X.shape, Y.shape)\n",
    "    return X, Y\n",
    "\n",
    "\n",
    "random.seed(42)\n",
    "random.shuffle(words)\n",
    "n1 = int(0.8*len(words))\n",
    "n2 = int(0.9*len(words))\n",
    "X_train, Y_train = build_dataset(words[:n1])\n",
    "X_dev, Y_dev = build_dataset(words[n1:n2])\n",
    "X_test, Y_test = build_dataset(words[n2:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utility func to compare grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cmp(s, dt, t):\n",
    "    ex = torch.all(dt == t.grad).item()\n",
    "    app = torch.allclose(dt, t.grad)\n",
    "    maxdiff = (dt - t.grad).abs().max().item()\n",
    "    print(f'{s:15s} | exact: {str(ex):5s} | approximate: {str(app):5s} | maxdiff: {maxdiff}')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4137\n"
     ]
    }
   ],
   "source": [
    "n_embed = 10 #dim of the char embeddings\n",
    "n_hidden = 64 #num of neurons in the hidden layer of MLP\n",
    "\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "C = torch.randn((vocab_size, n_embed), generator=g)\n",
    "\n",
    "#Layer1\n",
    "W1 = torch.randn((block_size*n_embed, n_hidden), generator=g) * (5/3)/((n_embed*block_size)**0.5) #kaining init\n",
    "b1 = torch.randn(n_hidden, generator=g) * 0.1 #bias is optional here since we use batchnorm after this which cancels out bias term\n",
    "\n",
    "#Layer2\n",
    "W2 = torch.randn((n_hidden, vocab_size), generator=g) * 0.1\n",
    "b2 = torch.randn(vocab_size, generator=g) * 0.1\n",
    "\n",
    "#BatchNorm Params\n",
    "bngain = torch.randn((1, n_hidden))*0.1 + 1.0\n",
    "bnbias = torch.randn((1, n_hidden))* 0.1\n",
    "\n",
    "\n",
    "parameters = [C, W1, b1, W2, b2, bngain, bnbias]\n",
    "print(sum(p.nelement() for p in parameters))\n",
    "for p in parameters:\n",
    "    p.requires_grad = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "n = batch_size\n",
    "\n",
    "#construct a minibatch\n",
    "ix = torch.randint(0, X_train.shape[0], (batch_size, ), generator=g)\n",
    "Xb, Yb = X_train[ix], Y_train[ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.3528, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#forward pass, split into small steps\n",
    "\n",
    "emb = C[Xb]\n",
    "embcat = emb.view(emb.shape[0], -1)\n",
    "\n",
    "#Linear Layer 1\n",
    "h_pre_bn = embcat @ W1 + b1 #hidden layer preact\n",
    "\n",
    "#Batchnorm layer\n",
    "bnmeani = 1/n * h_pre_bn.sum(0, keepdim=True)\n",
    "bndiff = h_pre_bn - bnmeani\n",
    "bndiff2 = bndiff**2\n",
    "bnvar = 1/(n-1) * (bndiff2).sum(0, keepdim=True) #Bessel's correctn, div by n-1 not n\n",
    "bnvar_inv = (bnvar + 1e-5)**-0.5\n",
    "bnraw = bndiff * bnvar_inv\n",
    "h_pre_act = bngain * bnraw + bnbias\n",
    "\n",
    "#Non linearity\n",
    "h = torch.tanh(h_pre_act) #hidden layer\n",
    "\n",
    "#Linear Layer 2\n",
    "logits = h @ W2 + b2 #output layer\n",
    "\n",
    "#cross entropy loss\n",
    "logit_maxes = logits.max(1, keepdim=True).values\n",
    "norm_logits = logits - logit_maxes #subs max for stability\n",
    "counts = norm_logits.exp()\n",
    "counts_sum = counts.sum(1, keepdim=True)\n",
    "counts_sum_inv = counts_sum**-1 #if 1/counts_sum is used, backprop wont be exact\n",
    "probs = counts * counts_sum_inv\n",
    "logprobs = probs.log()\n",
    "loss = -logprobs[range(n), Yb].mean()\n",
    "\n",
    "#Pytorch backward pass\n",
    "for p in parameters:\n",
    "    p.grad = None\n",
    "\n",
    "for t in [emb, embcat, h_pre_bn, bnmeani, bndiff, bndiff2, bnvar, \n",
    "          bnvar_inv, bnraw, h_pre_act, h, logits, logit_maxes, norm_logits, counts, \n",
    "          counts_sum, counts_sum_inv, probs, logprobs, loss]:\n",
    "    t.retain_grad()\n",
    "\n",
    "loss.backward()\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Backpropagate manually"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Cal grads of each of the intermediate variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logprobs        | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "#dlogprobs = d(Loss)/dlogprobs\n",
    "\n",
    "#loss = -(a + b + c)/3 ==> dloss/da = -1/3\n",
    "\n",
    "#a, b, c in logprobs participate in cal loss for rest grad will be zero\n",
    "\n",
    "dlogprobs = torch.zeros_like(logprobs)\n",
    "dlogprobs[range(n), Yb] = -1.0/n # n is the batchsize here, from each batch one prob contributes to loss, as indexed by Yb\n",
    "\n",
    "#check with pytorch\n",
    "cmp('logprobs', dlogprobs, logprobs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probs           | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "#dprobs = local der * dlogprobs -> 1/x * dlogprobs\n",
    "\n",
    "dprobs = (1.0/probs) * dlogprobs\n",
    "cmp('probs', dprobs, probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- dprobs will be boosted if probs is low and dlogprobs is non zero, which means cases where correct label has low prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 27]), torch.Size([32, 1]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts.shape, counts_sum_inv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 27])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dprobs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count_sum_inv is broadcasted to mul with counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counts          | exact: False | approximate: False | maxdiff: 0.003835804760456085\n",
      "counts_sum_inv  | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "#dcounts = count_sum_inv * dprobs \n",
    "#dcounts_sum_inv = sum(counts * dprobs, 1) : also since this is broadcasted to 27 cols, we sum the grad\n",
    "\n",
    "dcounts1 = counts_sum_inv * dprobs\n",
    "dcounts_sum_inv = (counts * dprobs).sum(1, keepdim=True)\n",
    "\n",
    "cmp('counts', dcounts1, counts)\n",
    "cmp('counts_sum_inv', dcounts_sum_inv, counts_sum_inv)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- dcounts does not match here since it is being used twice, to cal count_sum also, so grad will flow in from there as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counts_sum      | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "#dcount_sum = -counts_sum**-2 * dcounts_sum_inv\n",
    "\n",
    "dcounts_sum = -counts_sum**-2 * dcounts_sum_inv\n",
    "cmp('counts_sum', dcounts_sum, counts_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counts          | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "#2nd part of dcounts = 1 * dcounts_sum, grad dlows equally to all elements of the sum\n",
    "\n",
    "dcounts2 = 1 * dcounts_sum\n",
    "dcounts = dcounts1 + dcounts2\n",
    "cmp('counts', dcounts, counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dnorm_logits    | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "#dnorm_logits\n",
    "\n",
    "dnorm_logits = counts * dcounts\n",
    "cmp('dnorm_logits', dnorm_logits, norm_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dlogit_maxes    | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "dlogits1        | exact: False | approximate: True  | maxdiff: 6.984919309616089e-09\n"
     ]
    }
   ],
   "source": [
    "#dlogit_maxes; broadcasting happening here\n",
    "\n",
    "dlogit_maxes = (-1 * dnorm_logits).sum(1, keepdim=True)\n",
    "dlogits1 = dnorm_logits.clone()\n",
    "\n",
    "cmp('dlogit_maxes', dlogit_maxes, logit_maxes)\n",
    "cmp('dlogits1', dlogits1, logits)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6.9849e-09],\n",
       "        [ 1.3970e-09],\n",
       "        [-3.0268e-09],\n",
       "        [-9.3132e-10],\n",
       "        [ 1.8626e-09],\n",
       "        [-3.9581e-09],\n",
       "        [-2.0955e-09],\n",
       "        [ 9.3132e-10],\n",
       "        [-1.3970e-09],\n",
       "        [ 5.5879e-09],\n",
       "        [-3.7253e-09],\n",
       "        [ 4.4238e-09],\n",
       "        [-9.3132e-10],\n",
       "        [-2.7940e-09],\n",
       "        [ 3.4925e-09],\n",
       "        [-3.4925e-09],\n",
       "        [-2.7940e-09],\n",
       "        [ 2.3283e-09],\n",
       "        [ 0.0000e+00],\n",
       "        [-3.2596e-09],\n",
       "        [ 1.3970e-09],\n",
       "        [-5.5879e-09],\n",
       "        [ 9.3132e-10],\n",
       "        [-4.6566e-10],\n",
       "        [ 1.6298e-09],\n",
       "        [ 4.6566e-10],\n",
       "        [ 0.0000e+00],\n",
       "        [ 3.2596e-09],\n",
       "        [ 3.0268e-09],\n",
       "        [-9.3132e-10],\n",
       "        [ 1.3970e-09],\n",
       "        [ 1.3970e-09]], grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlogit_maxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- dlogit_maxes is very small and it should be since its substracted from logits and it should not impact probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dlogits         | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "#dlogits; second part; here grad should be only for max value and rest should be zero\n",
    "\n",
    "dlogits2 = F.one_hot(logits.max(1).indices, num_classes=logits.shape[1]) * dlogit_maxes\n",
    "dlogits = dlogits1 + dlogits2\n",
    "cmp('dlogits', dlogits, logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fda0684ccd0>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#indices where max value resides is 1, rest is zero\n",
    "plt.imshow(F.one_hot(logits.max(1).indices, num_classes=logits.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 27]),\n",
       " torch.Size([32, 64]),\n",
       " torch.Size([64, 27]),\n",
       " torch.Size([27]))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlogits.shape, h.shape, W2.shape, b2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([27, 64])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W2.T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dh              | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "#dh; logits = h@W + b; so dl/dh = dl/dlogits @ W.T; dh will be same dim as h\n",
    "dh = dlogits @  W2.T\n",
    "cmp('dh', dh, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dW2             | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "#dW2 should be same shape as W2 ie 64, 27; h.T @ dlogits\n",
    "dW2 = h.T @ dlogits\n",
    "cmp('dW2', dW2, W2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "db2             | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "#db2\n",
    "\n",
    "db2 = dlogits.sum(0)\n",
    "cmp('db2', db2, b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dh_pre_act      | exact: False | approximate: True  | maxdiff: 9.313225746154785e-10\n"
     ]
    }
   ],
   "source": [
    "#dh_pre_act; backprop through tanh\n",
    "\n",
    "dh_pre_act = (1.0 - h**2) * dh\n",
    "cmp('dh_pre_act', dh_pre_act, h_pre_act)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 64]),\n",
       " torch.Size([1, 64]),\n",
       " torch.Size([32, 64]),\n",
       " torch.Size([1, 64]))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_pre_act.shape, bngain.shape, bnraw.shape, bnbias.shape, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dbngain         | exact: False | approximate: True  | maxdiff: 1.862645149230957e-09\n"
     ]
    }
   ],
   "source": [
    "#bngain; h_pre_act = bngain * bnraw + bnbias; this is elementwise mul so its simpler\n",
    "\n",
    "dbngain = (bnraw * dh_pre_act).sum(0, keepdim=True)\n",
    "cmp('dbngain', dbngain, bngain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dbnraw          | exact: False | approximate: True  | maxdiff: 9.313225746154785e-10\n"
     ]
    }
   ],
   "source": [
    "dbnraw = (bngain * dh_pre_act)\n",
    "cmp('dbnraw', dbnraw, bnraw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dbnbias         | exact: False | approximate: True  | maxdiff: 1.862645149230957e-09\n"
     ]
    }
   ],
   "source": [
    "dbnbias = dh_pre_act.sum(0, keepdim=True)\n",
    "cmp('dbnbias', dbnbias, bnbias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
